{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Imprort calssifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bayes_classifier = joblib.load(\"ds_konle_clf.pkl\")\n",
    "clf = bayes_classifier\n",
    "count_vect = joblib.load(\"count_vect.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorizedata(path):\n",
    "    df = pd.read_csv(path, sep=\"\\t\", encoding=\"utf-8\", names=[\"text\", \"speech\"])\n",
    "    X_raw = df.text.values.astype('U')\n",
    "    X_all = count_vect.transform(X_raw)\n",
    "    return(X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Predicting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_data(vectors):\n",
    "    predicted = clf.predict(vectors)\n",
    "    \n",
    "    return(predicted)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Load unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## set path to meta.tsv\n",
    "metapath = \"/home/leo/Documents/DS_Speech/raw_data/unlabeled/schemakorpus/meta.tsv\"\n",
    "## read in meta.tsv\n",
    "corpus_df = pd.read_csv(metapath, sep=\"\\t\", encoding=\"utf-8\",header=0,skip_blank_lines=True)\n",
    "\n",
    "## prepare dataframe for predicted data\n",
    "corpus_df[\"ds_speak\"] = \"\"\n",
    "corpus_df.ds_speak = corpus_df.ds_speak.astype(object)\n",
    "\n",
    "## collect text form corpus\n",
    "for meta_row in corpus_df.itertuples():\n",
    "    \n",
    "    ## vectorize text\n",
    "    file_vectors = vectorizedata(meta_row.filepath)\n",
    "    \n",
    "    ## predict dataset\n",
    "    ds_speech = predict_data(file_vectors)  \n",
    "    \n",
    "    ## store predicted data in dataframe\n",
    "    \n",
    "    corpus_df.set_value((int(meta_row.Index)), 'ds_speak', ds_speech)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Save predicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['testcorpus_2.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump( corpus_df, 'testcorpus_2.pkl')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
